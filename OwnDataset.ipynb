{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: latin-1\n",
    "\n",
    "import mne\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "mat = scipy.io.loadmat('/Users/rramele/./GoogleDrive/Data/P300/p300-subject-21.mat')\n",
    "mat = scipy.io.loadmat('/Users/rramele/work/gsync/.//data/p300-subject-21.mat')\n",
    "\n",
    "mat = scipy.io.loadmat('/Users/rramele/work/capsule-5299343/code/data/p300-subject-26.mat')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(355904, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-336555355d6c>:13: RuntimeWarning: Channel locations not available. Disabling spatial colors.\n",
      "  fig=eeg_mne.plot_psd()\n",
      "<ipython-input-2-336555355d6c>:13: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations. \n",
      "  fig=eeg_mne.plot_psd()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-336555355d6c>:17: RuntimeWarning: Channel locations not available. Disabling spatial colors.\n",
      "  fig=eeg_mne.plot_psd()\n",
      "<ipython-input-2-336555355d6c>:17: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations. \n",
      "  fig=eeg_mne.plot_psd()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data point zero for the eight channels.  Should be in V.\n",
    "signal = mat['data'][0][0][0] * pow(10,6)\n",
    "\n",
    "print (signal.shape)\n",
    "\n",
    "ch_names=[ 'Fz'  ,  'Cz',    'P3' ,   'Pz'  ,  'P4'  ,  'PO7'   , 'PO8'   , 'Oz']\n",
    "ch_types= ['eeg'] * signal.shape[1]\n",
    "\n",
    "info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "\n",
    "eeg_mne = mne.io.array.RawArray(signal.T, info)\n",
    "\n",
    "fig=eeg_mne.plot_psd()\n",
    "\n",
    "fig=eeg_mne.filter(1,20)\n",
    "\n",
    "fig=eeg_mne.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names_events = ch_names + ['t_stim']+ ['t_type']\n",
    "ch_types_events = ch_types + ['misc'] + ['misc']\n",
    "\n",
    "t_stim = mat['data'][0][0][2]\n",
    "t_type = mat['data'][0][0][1]\n",
    "\n",
    "# Trials\n",
    "t_trials = mat['data'][0][0][3]\n",
    "\n",
    "# Flash matrix\n",
    "t_flash = mat['data'][0][0][4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique( t_type )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique( t_stim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flash at 90140, duration 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 38, 44, 56, 57, 59, 60, 61, 62, 63], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Flash at %d, duration %d' % (t_flash[1000,0], t_flash[1000,1]) )\n",
    "\n",
    "np.unique( t_flash[:,1] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(t_flash[:,1]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83051,    32,     7,     1], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_flash[926,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4038 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Found 4038 events, first five:\n",
      "[[7483    0    7]\n",
      " [7542    0    3]\n",
      " [7605    0   12]\n",
      " [7669    0    1]\n",
      " [7732    0    9]]\n"
     ]
    }
   ],
   "source": [
    "signal_events = np.concatenate([signal, t_stim, t_type],1)\n",
    "\n",
    "info_events = mne.create_info(ch_names_events,250, ch_types_events)\n",
    "\n",
    "eeg_events = mne.io.RawArray(signal_events.T, info_events)\n",
    "\n",
    "#eeg_events.plot(n_channels=10, scalings='auto')\n",
    "\n",
    "event_times = mne.find_events(eeg_events, consecutive=True, min_duration=0.0001, stim_channel='t_stim', shortest_event=1,verbose=True)\n",
    "\n",
    "print('Found %s events, first five:' % len(event_times))\n",
    "print(event_times[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  3, 12,  1,  9,  2, 10,  5, 11,  4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_times[0:10,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  3, 12,  1,  9,  2, 10,  5, 11,  4], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_flash[0:10,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7606,   32,   12,    1],\n",
       "       [7670,   32,    1,    1]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_flash[2:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Problem with experiment structure.  There arent enough events.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fe077317e82a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_flash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_flash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Problem with experiment structure.  There aren'\u001b[0m\u001b[0;34m't enough events.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Problem with experiment structure.  There arent enough events."
     ]
    }
   ],
   "source": [
    "np.unique(t_flash[:,0]).shape\n",
    "assert  np.unique(t_flash[:,0]).shape[0] == 4200, 'Problem with experiment structure.  There aren''t enough events.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.unique(t_stim)\n",
    "t_stim[t_stim==12].shape\n",
    "mat['data'][0][0][3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_times = mne.find_events(eeg_events, stim_channel='t_type')\n",
    "\n",
    "tmin = 0\n",
    "tmax = 0.8\n",
    "\n",
    "epochs = mne.Epochs(eeg_mne, event_times, { 'second':2 }, tmin, tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Hits:')\n",
    "print ('Epochs x channels x time')\n",
    "print (epochs.get_data().shape)\n",
    "\n",
    "evoked = epochs.average()\n",
    "evoked.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_times = mne.find_events(eeg_events, stim_channel='t_type')\n",
    "\n",
    "tmin = 0\n",
    "tmax = 0.8\n",
    "\n",
    "epochs = mne.Epochs(eeg_mne, event_times, {'first':1}, tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Nohits:')\n",
    "print ('Epochs x channels x time')\n",
    "print (epochs.get_data().shape)\n",
    "\n",
    "evoked = epochs.average()\n",
    "evoked.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_mne.plot(scalings='auto',n_channels=8,events=event_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.read_montage('standard_1020')\n",
    "\n",
    "eeg_mne.set_montage(montage)\n",
    "\n",
    "eeg_mne.plot_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = { 'first':1, 'second':2 }\n",
    "#baseline = (0.0, 0.2)\n",
    "#reject = {'eeg': 70 * pow(10,6)}\n",
    "reject = None\n",
    "epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                baseline=None, reject=reject, preload=True,\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create classification pipeline\n",
    "clf = make_pipeline(mne.preprocessing.Xdawn(n_components=3),\n",
    "                    mne.decoding.Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l1')\n",
    "                    )\n",
    "\n",
    "labels = epochs.events[:, -1]\n",
    "lbls = labels\n",
    "\n",
    "# Cross validator\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "epochs.resample(20, npad=\"auto\")\n",
    "\n",
    "print ('Epochs x channels x time')\n",
    "print (epochs.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do cross-validation\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    cf=clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])\n",
    "\n",
    "prds = preds\n",
    "\n",
    "# Classification report\n",
    "target_names = ['nohit', 'hit']\n",
    "\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print (cm)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalavgacc=[]\n",
    "print ('Averaged classification per trials (20 reps vs 100 reps)')\n",
    "\n",
    "repetitions=120\n",
    "\n",
    "# Extracting for each letter-trial the epochs for each class.\n",
    "for trial in range(0,35):\n",
    "    epochstrial = epochs[0+repetitions*trial:repetitions*trial+repetitions]\n",
    "\n",
    "    epochstrial1 = epochstrial['first']\n",
    "    epochstrial2 = epochstrial['second']\n",
    "\n",
    "    print ('Epochs x channels x time')\n",
    "    print (epochstrial.get_data().shape)\n",
    "\n",
    "    if (trial==0):\n",
    "        evoked_nohit = epochstrial1.average()\n",
    "        epochs_data = np.array([evoked_nohit.data])\n",
    "    else:\n",
    "        epochs_data = np.concatenate((epochs_data, [epochstrial1.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochstrial2.average().data]), axis=0)\n",
    "\n",
    "\n",
    "#nave = len(epochs_data)\n",
    "#evokeds = mne.EvokedArray(evoked_data, info=info, tmin=-0.2,comment='Arbitrary', nave=nave)\n",
    "labels = np.array([1,2]*35)\n",
    "\n",
    "print ('Randomize values...')\n",
    "#labels = np.random.randint(1,3,70)\n",
    "\n",
    "events = np.asarray([np.arange(70)+1,np.zeros(70), np.array([1,2]*35) ])\n",
    "events = events.T\n",
    "\n",
    "events = events.astype(int)\n",
    "\n",
    "\n",
    "events[:,2] = labels\n",
    "\n",
    "# Cross validator\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "custom_epochs = mne.EpochsArray(epochs_data, info, events, tmin, event_id)\n",
    "\n",
    "# Do cross-validation\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(custom_epochs, labels):\n",
    "    cf=clf.fit(custom_epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(custom_epochs[test])\n",
    "\n",
    "\n",
    "test = range(30,70)\n",
    "cf = clf.fit(custom_epochs[0:30], labels[0:30])\n",
    "preds[test] = clf.predict(custom_epochs[test])\n",
    "\n",
    "preds = preds[test]\n",
    "labels = labels[test]\n",
    "\n",
    "# Classification report\n",
    "target_names = ['nohit', 'hit']\n",
    "\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print (cm)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))\n",
    "\n",
    "print('Accuracy per letter trial:'+str(acc))\n",
    "\n",
    "globalavgacc.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalperformance=[]\n",
    "\n",
    "print ('Averaged classification per row/column')\n",
    "\n",
    "event_times = mne.find_events(eeg_events, stim_channel='t_stim')\n",
    "event_id = {'Row1':1,'Row2':2,'Row3':3,'Row4':4,'Row5':5,'Row6':6,'Col1':7,'Col2':8,'Col3':9,'Col4':10,'Col5':11,'Col6':12}\n",
    "\n",
    "epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                baseline=None, reject=reject, preload=True,\n",
    "                verbose=True)\n",
    "\n",
    "repetitions=120\n",
    "\n",
    "stims = event_times[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls[0+120*0:0+120*0+24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero tengo que agarrar la lista de labels y asignar a los 420 (35x12)\n",
    "# el label que le corresponde a cada uno.  Es decir de los primeros 12, 10\n",
    "# son no hits y 2 hits.\n",
    "hlbls = []\n",
    "hpreds = []\n",
    "classlabels=np.asarray([])\n",
    "for trial in range(0,35):\n",
    "    a=np.zeros((12*10,2))\n",
    "    a[:,0] = stims[0+120*trial:0+120*trial+120]\n",
    "    a[:,1] = lbls[0+120*trial:0+120*trial+120]\n",
    "\n",
    "    b=np.zeros((12,1))\n",
    "\n",
    "    for i in range(1,13):\n",
    "        b[i-1] = np.unique(a[a[:,0]==i,1])\n",
    "\n",
    "    for i in range(0,6):\n",
    "        if (b[i]==2):\n",
    "            r = i+1\n",
    "\n",
    "    for i in range(6,12):\n",
    "        if (b[i]==2):\n",
    "            c = i+1\n",
    "\n",
    "    classlabels = np.append( classlabels, b )\n",
    "\n",
    "    assert (r!=0 and c!=0), 'Error %d,%d' % (r,c) \n",
    "    hlbls.append( (r,c) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classlabels = np.array(classlabels)\n",
    "\n",
    "classlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classlabels[classlabels==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stims[stims==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hlbls[0][1])\n",
    "\n",
    "def SpellMeLetter(row, col):\n",
    "    spellermatrix = [ ['A','B','C','D','E','F'],\n",
    "                    [ 'G','H','I','J','K','L'],\n",
    "                [ 'M','N','O','P','Q','R'],\n",
    "                [ 'S','T','U','V','W','X'],\n",
    "                [ 'Y','Z','1','2','3','4'],\n",
    "                [ '5','6','7','8','9','_'] ]\n",
    "\n",
    "    return spellermatrix[row-1][col-1-6]\n",
    "\n",
    "for i in range(0,35):\n",
    "    print(SpellMeLetter(hlbls[i][0],hlbls[i][1]),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classlabels[classlabels==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego necesito calcular los 420 averaging (de repetitions)\n",
    "\n",
    "# Finalmente aprendo con 180 y me fijo si predigo los 240\n",
    "\n",
    "# De los 240 adivino 20 letras (de a pares) y con eso calculo la performance\n",
    "\n",
    "for trial in range(0,35):\n",
    "    epochstrial = epochs[0+repetitions*trial:repetitions*trial+repetitions]\n",
    "\n",
    "    epochr1 = epochstrial['Row1']\n",
    "    epochr2 = epochstrial['Row2']\n",
    "    epochr3 = epochstrial['Row3']\n",
    "    epochr4 = epochstrial['Row4']\n",
    "    epochr5 = epochstrial['Row5']\n",
    "    epochr6 = epochstrial['Row6']\n",
    "\n",
    "    epochc1 = epochstrial['Col1']\n",
    "    epochc2 = epochstrial['Col2']\n",
    "    epochc3 = epochstrial['Col3']\n",
    "    epochc4 = epochstrial['Col4']\n",
    "    epochc5 = epochstrial['Col5']\n",
    "    epochc6 = epochstrial['Col6']\n",
    "\n",
    "    if (trial==0):\n",
    "        epochs_data = np.array([epochr1.average().data])\n",
    "    else:\n",
    "        epochs_data = np.concatenate((epochs_data, [epochr1.average().data]), axis=0)\n",
    "\n",
    "    epochs_data = np.concatenate((epochs_data, [epochr2.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochr3.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochr4.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochr5.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochr6.average().data]), axis=0)\n",
    "\n",
    "    epochs_data = np.concatenate((epochs_data, [epochc1.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochc2.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochc3.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochc4.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochc5.average().data]), axis=0)\n",
    "    epochs_data = np.concatenate((epochs_data, [epochc6.average().data]), axis=0)\n",
    "\n",
    "# There are 420 epochs, which correspond to 35 letters, in groups of 12.\n",
    "events=np.array([np.arange(420),np.zeros(420), classlabels])\n",
    "events = events.T\n",
    "events = events.astype(int)\n",
    "\n",
    "event_id = { 'first':1, 'second':2 }\n",
    "custom_epochs = mne.EpochsArray(epochs_data, info, events, tmin, event_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performance Classification of Averaged Epochs')\n",
    "test = range(180,420)\n",
    "classpreds = np.empty(len(classlabels))\n",
    "cf = clf.fit(custom_epochs[0:180], classlabels[0:180])\n",
    "classpreds[test] = clf.predict(custom_epochs[test])\n",
    "\n",
    "preds = classpreds[test]\n",
    "labels = classlabels[test]\n",
    "\n",
    "\n",
    "# Classification report\n",
    "target_names = ['nohit', 'hit']\n",
    "\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print (cm)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))\n",
    "\n",
    "globalperformance.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performance Classification of Averaged Epochs')\n",
    "test = range(180,420)\n",
    "cf = clf.fit(custom_epochs[0:180], classlabels[0:180])\n",
    "\n",
    "classpreds = np.empty ((480,2))\n",
    "\n",
    "classpreds[test,:] = clf.predict_proba(custom_epochs[test])\n",
    "\n",
    "hpreds = []\n",
    "\n",
    "for trial in range(15,35):\n",
    "    #print('Row')\n",
    "    for i in range(0,6):\n",
    "        preds = classpreds[trial*12+i]\n",
    "        #print ( preds[1] )\n",
    "        labels = classlabels[trial*12+i]\n",
    "\n",
    "    #print (  np.argmin( classpreds[trial*12+0:trial*12+6]))\n",
    "    r = np.argmin( classpreds[trial*12+0:trial*12+6,1])+1\n",
    "    \n",
    "\n",
    "    #print('Col')\n",
    "    for i in range(6,12):\n",
    "        preds = classpreds[trial*12+i]\n",
    "        #print ( preds[1] )\n",
    "        labels = classlabels[trial*12+i]\n",
    "\n",
    "    #print (  np.argmin( classpreds[trial*12+6:trial*12+12]))\n",
    "    c = np.argmin( classpreds[trial*12+6:trial*12+12,1])+1\n",
    "\n",
    "    hpreds.append( (r,c) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,35):\n",
    "    print(SpellMeLetter(hlbls[i][0],hlbls[i][1]),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,35):\n",
    "    print(SpellMeLetter(hpreds[i-15][0],hpreds[i-15][1]),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalperformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
